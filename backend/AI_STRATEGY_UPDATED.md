# üéØ CHI·∫æN L∆Ø·ª¢C AI C√ÇN B·∫∞NG - T·∫¨N D·ª§NG GROQ

**Ng√†y c·∫≠p nh·∫≠t:** 19/12/2025  
**D·ª±a tr√™n:** Ph√¢n t√≠ch th·ª±c t·∫ø c√°c providers c√≥ s·∫µn

---

## üìä T√ìM T·∫ÆT PROVIDERS

### üü¢ Tier 1: Fast + Free (Groq)

Groq cung c·∫•p **NHI·ªÄU models tuy·ªát v·ªùi** v·ªõi free tier r·ªông r√£i:

| Model | Strengths | Use Cases | Latency |
|-------|-----------|-----------|---------|
| **Llama 3.3 70B Versatile** | General purpose, reasoning, multilingual | AI Tutor ch√≠nh, general chat | 0.5-1.5s |
| **Qwen 3 32B** | Math, logic, technical reasoning | Math tutoring, logic problems | 0.8-2s |
| **Llama 4 Scout** | Vision, multimodal | Image analysis (future) | 1-2s |
| **Whisper Large v3** | Speech to text, transcription | Audio transcription (future) | 1-3s |
| **GPT OSS 120B** | Advanced reasoning (backup) | Complex reasoning fallback | 1-2s |

**‚úÖ ∆Øu ƒëi·ªÉm:**
- Free tier r·ªông r√£i
- Latency th·∫•p (< 2s)
- Nhi·ªÅu models chuy√™n bi·ªát
- Rate limit cao

**‚ö†Ô∏è H·∫°n ch·∫ø:**
- Context window nh·ªè h∆°n (32K-128K)
- Kh√¥ng c√≥ model code chuy√™n s√¢u

---

### üü° Tier 1.5: Free Fallback (Google AI)

| Model | Context | Use Cases |
|-------|---------|-----------|
| **Gemini 2.5 Flash** | 1M tokens | General fallback, batch processing |

**‚úÖ ∆Øu ƒëi·ªÉm:**
- Context window l·ªõn (1M)
- Free tier
- ·ªîn ƒë·ªãnh cao

**‚ö†Ô∏è H·∫°n ch·∫ø:**
- Ch·ªâ c√≥ 1 model
- Latency cao h∆°n Groq (2-4s)
- Rate limit th·∫•p h∆°n (60 req/min)

---

### üîµ Tier 2: Powerful + Local (ProxyPal)

**‚ö†Ô∏è CH·ªà D√ôNG KHI C·∫¶N THI·∫æT - Ph·ª• thu·ªôc v√†o t√†i kho·∫£n c√° nh√¢n**

| Model | Context | Strengths |
|-------|---------|-----------|
| **Gemini 3 Pro Preview** | 2M tokens | Large context, content repurposing |
| **Qwen 3 Coder Plus** | 32K tokens | Code review, technical grading |
| **Qwen 3 Coder Flash** | 128K tokens | Fast code generation |

**‚úÖ ∆Øu ƒëi·ªÉm:**
- Models r·∫•t m·∫°nh
- Context c·ª±c l·ªõn (Gemini 3: 2M)
- Chuy√™n s√¢u v·ªÅ code (Qwen Coder)

**‚ö†Ô∏è H·∫°n ch·∫ø:**
- C·∫ßn ch·∫°y ProxyPal local
- Latency cao (3-8s)
- Ph·ª• thu·ªôc subscription c√° nh√¢n
- Ch·ªâ d√πng dev/testing

---

### üî¥ Tier 3: Premium (MegaLLM)

**üö® D√ôNG C·ª∞C K·ª≤ TI·∫æT KI·ªÜM - $150 credit kh√¥ng h·ªìi ph·ª•c**

| Model | Input/Output | Use Cases |
|-------|--------------|-----------|
| **Claude Sonnet 4.5** | $3/$15 per M | Critical decisions, grade appeals |
| **Claude Opus 4.5** | $5/$25 per M | Highest quality needed |

**‚úÖ ∆Øu ƒëi·ªÉm:**
- Ch·∫•t l∆∞·ª£ng cao nh·∫•t
- Reasoning t·ªët nh·∫•t
- Chuy√™n s√¢u nhi·ªÅu lƒ©nh v·ª±c

**‚ö†Ô∏è H·∫°n ch·∫ø:**
- R·∫•t ƒë·∫Øt
- Credit c√≥ gi·ªõi h·∫°n ($150 total)
- Ch·ªâ d√πng cho critical operations

---

## üéØ CHI·∫æN L∆Ø·ª¢C M·ªöI

### Nguy√™n t·∫Øc c·ªët l√µi

```
1. Groq FIRST - T·∫≠n d·ª•ng t·ªëi ƒëa c√°c models c·ªßa Groq
2. Google Fallback - D√πng khi Groq kh√¥ng available
3. ProxyPal RARELY - Ch·ªâ d√πng cho dev ho·∫∑c tasks c·∫ßn context l·ªõn
4. MegaLLM CRITICAL ONLY - Ch·ªâ d√πng cho quy·∫øt ƒë·ªãnh quan tr·ªçng
```

### Ph√¢n b·ªï theo Use Case

#### 1. AI Tutor (Chatbot h·ªçc t·∫≠p)

```
Priority 1: Groq Llama 3.3 70B (General)
   ‚Üì (if math question)
Priority 1: Groq Qwen 3 32B (Math)
   ‚Üì (if complex reasoning)
Priority 1: Groq Llama 3.3 70B (Reasoning)
   ‚Üì (if all Groq fail)
Fallback: Google Gemini 2.5 Flash
   ‚Üì (if all fail)
Error: "AI t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng"
```

**T·ª∑ l·ªá s·ª≠ d·ª•ng mong ƒë·ª£i:**
- Groq: 85-90%
- Google: 10-15%
- ProxyPal: 0% (production), <5% (dev)

#### 2. Quiz Generator

```
Priority 1: Groq Llama 3.3 70B (Content < 32K tokens)
   ‚Üì (if content > 32K tokens)
Priority 2: Google Gemini 2.5 Flash (Context 1M)
   ‚Üì (if need very large context > 1M)
Priority 3: ProxyPal Gemini 3 Pro (Context 2M) - DEV ONLY
   ‚Üì (if critical final exam)
Priority 4: MegaLLM Claude Sonnet 4.5
```

**T·ª∑ l·ªá s·ª≠ d·ª•ng mong ƒë·ª£i:**
- Groq: 60-70%
- Google: 25-35%
- ProxyPal: 0% (production), <5% (dev)
- MegaLLM: <1% (critical exams only)

#### 3. AI Grader

**Code Grading:**
```
Priority 1: Groq Llama 3.3 70B (Simple code < 500 lines)
   ‚Üì (if complex code or need deep review)
Priority 2: ProxyPal Qwen Coder Plus - DEV ONLY
   ‚Üì (if grade appeal)
Priority 3: MegaLLM Claude Sonnet 4.5
```

**Essay Grading:**
```
Priority 1: Groq Llama 3.3 70B (Essays < 32K tokens)
   ‚Üì (if large essay)
Priority 2: Google Gemini 2.5 Flash
   ‚Üì (if grade appeal)
Priority 3: MegaLLM Claude Sonnet 4.5
```

**T·ª∑ l·ªá s·ª≠ d·ª•ng mong ƒë·ª£i:**
- Groq: 70-80%
- Google: 15-20%
- ProxyPal: 0% (production), <5% (dev)
- MegaLLM: <2% (appeals only)

#### 4. Content Repurposing (Video ‚Üí Summary)

```
Priority 1: Google Gemini 2.5 Flash (Context 1M)
   ‚Üì (if transcript > 1M tokens - DEV ONLY)
Priority 2: ProxyPal Gemini 3 Pro (Context 2M)
```

**T·ª∑ l·ªá s·ª≠ d·ª•ng mong ƒë·ª£i:**
- Google: 95-98%
- ProxyPal: 0% (production), 2-5% (dev)

---

## üí∞ D·ª∞ PH√ìNG CHI PH√ç

### Scenario 1: Pure Free Tier (Production Recommended)

**Setup:**
- Groq: Primary (85-90% usage)
- Google: Fallback (10-15% usage)
- ProxyPal: Disabled
- MegaLLM: Disabled

**Chi ph√≠:** **$0/th√°ng** ‚úÖ

**Limitations:**
- Kh√¥ng c√≥ grade appeals
- Kh√¥ng c√≥ premium features
- Context gi·ªõi h·∫°n 1M tokens

---

### Scenario 2: With Grade Appeals (Production with Premium)

**Setup:**
- Groq: Primary (85-90%)
- Google: Fallback (10-15%)
- ProxyPal: Disabled
- MegaLLM: Critical only (<2%)

**Chi ph√≠ d·ª± ki·∫øn:**
- 100 students √ó 2 appeals/month = 200 appeals
- Average 5K tokens input + 2K output per appeal
- Cost: 200 √ó (5K √ó $3 + 2K √ó $15) / 1M = $9/month

**Total:** **~$10/month** from $150 credit = **15 th√°ng s·ª≠ d·ª•ng**

---

### Scenario 3: Development v·ªõi ProxyPal

**Setup:**
- Groq: Primary (70-80%)
- Google: Fallback (15-20%)
- ProxyPal: Dev testing (<5%)
- MegaLLM: Disabled

**Chi ph√≠:** **$0/th√°ng** (d√πng subscription c√° nh√¢n)

---

## üîß C·∫§U H√åNH KHUY·∫æN NGH·ªä

### Production (Recommended)

```bash
# Tier 1: Groq (Primary)
GROQ_API_KEY=your-key
GROQ_MODEL_DEFAULT=llama-3.3-70b-versatile
GROQ_MODEL_REASONING=llama-3.3-70b-versatile
GROQ_MODEL_MATH=qwen-3-32b

# Tier 1.5: Google (Fallback)
GEMINI_API_KEY=your-key
GEMINI_MODEL=gemini-2.5-flash

# Tier 2: ProxyPal (Disabled)
PROXYPAL_ENABLED=false

# Tier 3: MegaLLM (Enabled but limited)
MEGALM_API_KEY=your-key-if-you-want-appeals
MEGALM_BASE_URL=https://api.megallm.com

# Features
AI_TUTOR_ENABLED=true
AI_QUIZ_GENERATOR_ENABLED=true
AI_GRADER_ENABLED=true
AI_CONTENT_REPURPOSING_ENABLED=false  # B·∫≠t khi c·∫ßn
```

### Development

```bash
# Same as production but enable ProxyPal
PROXYPAL_ENABLED=true
PROXYPAL_BASE_URL=http://localhost:8317

# Test v·ªõi powerful models
AI_CONTENT_REPURPOSING_ENABLED=true
```

---

## üìà MONITORING & OPTIMIZATION

### Metrics c·∫ßn theo d√µi

1. **Provider Usage Distribution**
   ```
   Groq:      85-90%  ‚úÖ Healthy
   Google:    10-15%  ‚úÖ Good fallback rate
   ProxyPal:  0-5%    ‚úÖ Dev only
   MegaLLM:   <2%     ‚úÖ Critical only
   ```

2. **Latency Targets**
   ```
   Groq:      < 2s    ‚úÖ
   Google:    < 4s    ‚úÖ
   ProxyPal:  < 8s    ‚ö†Ô∏è (Dev acceptable)
   ```

3. **Cost Tracking**
   ```
   MegaLLM usage: < $10/month
   Remaining credit: Monitor weekly
   ```

### Optimization Actions

**If Groq usage < 80%:**
- Ki·ªÉm tra availability
- Review fallback logic
- Optimize question classification

**If MegaLLM usage > $15/month:**
- Review critical operation criteria
- Consider disabling grade appeals
- Add human review layer

**If latency > targets:**
- Check network
- Review provider selection logic
- Consider caching strategies

---

## üöÄ IMPLEMENTATION CHECKLIST

- [x] Update env.example v·ªõi Groq multi-model config
- [x] Update env.config.ts v·ªõi Groq models object
- [x] Update AI Orchestrator v·ªõi specialized model selection
- [x] Create strategy document
- [ ] Test Groq Math model v·ªõi math questions
- [ ] Test fallback chain: Groq ‚Üí Google
- [ ] Monitor provider distribution in logs
- [ ] Setup MegaLLM (optional, for grade appeals)

---

## üìö REFERENCES

- [Groq Console](https://console.groq.com/) - API keys & model list
- [Google AI Studio](https://aistudio.google.com/) - Gemini API
- [ProxyPal](https://proxypal.ai/) - Local gateway setup
- [AI Orchestrator Code](src/modules/ai/orchestrator/ai-orchestrator.ts)

---

**‚úÖ Chi·∫øn l∆∞·ª£c n√†y cho ph√©p:**
1. ‚úÖ D√πng free tier t·ªëi ƒëa (Groq + Google)
2. ‚úÖ T·∫≠n d·ª•ng nhi·ªÅu specialized models c·ªßa Groq
3. ‚úÖ Ti·∫øt ki·ªám ProxyPal cho dev/testing only
4. ‚úÖ D·ª± ph√≤ng MegaLLM cho critical operations
5. ‚úÖ Chi ph√≠ production: $0-10/th√°ng

**üéØ M·ª•c ti√™u cu·ªëi c√πng: Zero cost trong 90% use cases, premium available khi c·∫ßn!**
