# üõ†Ô∏è Roadmap Backend: Groq Multimodal (Speech + Vision) + Tool Use

**T√†i li·ªáu (Document):** 15 - Backend Roadmap  
**Phi√™n b·∫£n (Version):** 1.0  
**C·∫≠p nh·∫≠t g·∫ßn nh·∫•t (Last Updated):** December 27, 2025  
**M·ª•c ti√™u:** T·ª´ ‚ÄúGroq text chat‚Äù ‚Üí m·ªü r·ªông sang STT/Vision/Tool-use ƒë·ªÉ c√≥ AI features hi·ªán ƒë·∫°i h∆°n.

---

## 1) Tr·∫°ng th√°i hi·ªán t·∫°i (codebase)

- C√≥ `GroqProvider` d√πng OpenAI-compatible `POST /v1/chat/completions` (text-only).
- `AIOrchestrator` ƒë√£ init Groq: default + math + reasoning.
- `env.ai.groq.models` c√≥ `vision` v√† `speech` nh∆∞ng ch∆∞a ƒë∆∞·ª£c g·ªçi ·ªü ƒë√¢u.
- Video analysis hi·ªán n·∫±m ·ªü `LessonAnalysisService` v√† ph·ª• thu·ªôc `GeminiVideoService`.

---

## 2) Thi·∫øt k·∫ø m·ªü r·ªông provider layer (kh√¥ng ph√° API c≈©)

### 2.1 M·ªü r·ªông interface ·ªü provider layer
Hi·ªán `AIGenerateRequest` ch·ªâ c√≥ `prompt/systemPrompt`. ƒê·ªÉ h·ªó tr·ª£ tool-use & multimodal, ƒë·ªÅ xu·∫•t th√™m **interface m·ªõi** (kh√¥ng s·ª≠a breaking):

- `AIChatMessage` (role, content)
- `AIContentPart` (text | image | audio-ref)
- `AIToolSchema` (name, description, jsonSchema)
- `AIToolCall` (name, arguments)

V·∫´n gi·ªØ `generateContent()` cho text-only.

### 2.2 Groq speech-to-text client
Implement th√™m method (g·ª£i √Ω):
- `GroqProvider.transcribeAudio({ filePath|buffer, language?, prompt?, temperature? })`
- g·ªçi OpenAI-compatible endpoint (th∆∞·ªùng l√† `/v1/audio/transcriptions`).

### 2.3 Groq vision chat
Implement method:
- `GroqProvider.generateVisionContent({ messages: [ {role, contentParts:[text + image]} ] })`
- encode ·∫£nh base64 ho·∫∑c g·ª≠i URL (tu·ª≥ API h·ªó tr·ª£).

### 2.4 Tool use / function calling
N·∫øu model/endpoint h·ªó tr·ª£ `tools` (OpenAI-style) th√¨:
- add optional `tools` + `tool_choice` v√†o payload chat completions
- parse `tool_calls` t·ª´ response

---

## 3) Service layer m·ªõi

### 3.1 `GroqSpeechService`
- wrapper g·ªçi STT, retry, chunking, normalize transcript.

### 3.2 `GroqVisionService`
- caption/OCR cho images.

### 3.3 `VideoUnderstandingV2Service`
- orchestrate pipeline:
  1) download video
  2) extract audio (ffmpeg)
  3) transcribe (groq speech)
  4) sample frames (ffmpeg)
  5) vision caption/OCR
  6) fusion reasoning (groq reasoning)
  7) output JSON schema

---

## 4) T√≠ch h·ª£p v√†o Lesson Analysis (gi·ªØ c≈© + th√™m m·ªõi)

- `LessonAnalysisService.analyzeVideoContent()`:
  - `AI_VIDEO_PIPELINE=legacy` ‚Üí d√πng GeminiVideoService nh∆∞ hi·ªán t·∫°i
  - `AI_VIDEO_PIPELINE=v2` ‚Üí d√πng VideoUnderstandingV2Service

**Y√™u c·∫ßu:** kh√¥ng xo√° code/config legacy ƒë·ªÉ c√≥ ƒë∆∞·ªùng quay l·∫°i.

---

## 5) C√°c endpoint/API c·∫ßn b·ªï sung (theo docs/AI/10_API_DESIGN.md)

ƒê·ªÅ xu·∫•t th√™m (P0):
- `POST /api/v1/ai/video/analyze` (async) ‚Üí tr·∫£ `jobId` + polling
- `GET /api/v1/ai/video/jobs/:jobId`

Ho·∫∑c t√≠ch h·ª£p lu√¥n v√†o lesson analysis:
- `POST /api/v1/ai/lesson/:lessonId/analyze` (ƒë√£ c√≥ logic) v√† internal worker.

---

## 6) H·∫° t·∫ßng & dependency

- C·∫ßn `ffmpeg` tr√™n m√°y ch·∫°y backend (dev/prod).  
  - N·∫øu backend ch·∫°y container: add ffmpeg v√†o image.
- Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc video download + s·ªë frame.
- Cache: Redis (ƒë√£ c√≥) + disk temp.

---

## 7) Ki·ªÉm th·ª≠ & quan s√°t (observability)

- Unit tests:
  - parse STT response
  - parse vision response
  - fusion JSON schema validation
- Integration tests:
  - video nh·ªè (10‚Äì30s) ‚Üí transcript + summary
- Logging:
  - log `provider/model` cho t·ª´ng stage
  - latency per stage
- Safety:
  - size limit, timeout, input URL allowlist (n·∫øu c·∫ßn)

---

## 8) Ph√¢n k·ª≥ (ph√π h·ª£p th·ª±c t·∫ø)

### Sprint 1 (P0)
- GroqSpeechService + audio transcription
- VideoUnderstandingV2: audio-only (kh√¥ng vision) ‚Üí ƒë·ªß ƒë·ªÉ kh√¥i ph·ª•c ‚Äútranscript + key points‚Äù
- G·∫Øn v√†o LessonAnalysis theo `AI_VIDEO_PIPELINE=v2`

### Sprint 2 (P0/P1)
- Frame sampling + vision caption/OCR
- Fusion reasoning ƒë·∫ßy ƒë·ªß ‚Üí slide outline

### Sprint 3 (P1)
- Image-based grading (assignment submissions)
- Tool-use cho tutor (getLessonContext, getProgress)
