# üí¨ TR·ª¢ GI·∫¢NG AI - CHATBOT H·ªñ TR·ª¢ H·ªåC T·∫¨P

**T√†i li·ªáu:** 05 - AI Tutor  
**Phi√™n b·∫£n:** 2.0  
**C·∫≠p nh·∫≠t:** 17 th√°ng 12, 2025  
**∆Øu ti√™n:** P0 (Gi√° tr·ªã cao nh·∫•t)

---

## üìñ T·ªîNG QUAN

T√≠nh nƒÉng Tr·ª£ Gi·∫£ng AI cung c·∫•p h·ªó tr·ª£ h·ªçc t·∫≠p th·ªùi gian th·ª±c cho sinh vi√™n th√¥ng qua chatbot t∆∞∆°ng t√°c. H·ªá th·ªëng c√≥ kh·∫£ nƒÉng tr·∫£ l·ªùi c√¢u h·ªèi, gi·∫£i th√≠ch kh√°i ni·ªám, v√† cung c·∫•p g·ª£i √Ω h·ªçc t·∫≠p ƒë∆∞·ª£c c√° nh√¢n h√≥a.

### Gi√° tr·ªã kinh doanh
- ‚≠ê **H·ªó tr·ª£ 24/7:** C√°c sinh vi√™n c√≥ th·ªÉ h·ªçc b·∫•t k·ª≥ l√∫c n√†o
- ‚≠ê **Gi·∫£m √°p l·ª±c:** Gi·∫£m 40% c√¢u h·ªèi g·ª≠i cho gi√°o vi√™n
- ‚≠ê **C·∫£i thi·ªán k·∫øt qu·∫£:** +15% t·ª∑ l·ªá ho√†n th√†nh kh√≥a h·ªçc
- ‚≠ê **TƒÉng t∆∞∆°ng t√°c:** Sinh vi√™n tham gia +25%

### Th√¥ng s·ªë k·ªπ thu·∫≠t
- **M√¥ h√¨nh ch√≠nh:** Groq Llama 3 70B (< 2 gi√¢y)
- **M√¥ h√¨nh d·ª± ph√≤ng:** Google Gemini Flash (1-3 gi√¢y)
- **D·ªØ li·ªáu ng·ªØ c·∫£nh:** L·ªãch s·ª≠ h·ªôi tho·∫°i + th√¥ng tin kh√≥a h·ªçc
- **Ki·ªÉu k·∫øt n·ªëi:** WebSocket cho ph·∫£n h·ªìi th·ªùi gian th·ª±c

---

## üèóÔ∏è KI·∫æN TR√öC H·ªÜ TH·ªêNG

### Lu·ªìng ho·∫°t ƒë·ªông

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              SINH VI√äN H·ªéI C√ÇU H·ªéI                          ‚îÇ
‚îÇ  Chat UI ‚Üí G·ª≠i message qua WebSocket                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              BACKEND - MESSAGE ROUTER                        ‚îÇ
‚îÇ  - Nh·∫≠n message t·ª´ WebSocket                                ‚îÇ
‚îÇ  - Ki·ªÉm tra cache nhanh                                     ‚îÇ
‚îÇ  - X√°c th·ª±c ng·ªØ c·∫£nh ng∆∞·ªùi d√πng                             ‚îÇ
‚îÇ  - G·ª≠i t·ªõi AI Orchestrator                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              AI ORCHESTRATOR                                 ‚îÇ
‚îÇ  Ph√¢n lo·∫°i c√¢u h·ªèi ‚Üí Ch·ªçn m√¥ h√¨nh                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ               ‚îÇ               ‚îÇ
    C√¢u h·ªèi ƒë∆°n     C√¢u h·ªèi kh√≥    C√¢u h·ªèi code
    gi·∫£n (th∆∞·ªùng)   (c·∫ßn logic)    (c·∫ßn k·ªπ thu·∫≠t)
         ‚îÇ               ‚îÇ               ‚îÇ
         ‚ñº               ‚ñº               ‚ñº
    Groq Llama 3    Google Flash    Qwen Coder
    (0.5-1.5s)      (1-3s)          (2-5s)
         ‚îÇ               ‚îÇ               ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              GENERATE RESPONSE                               ‚îÇ
‚îÇ  - AI model x·ª≠ l√Ω c√¢u h·ªèi                                   ‚îÇ
‚îÇ  - T√≠ch h·ª£p ng·ªØ c·∫£nh h·ªçc t·∫≠p sinh vi√™n                      ‚îÇ
‚îÇ  - Format c√¢u tr·∫£ l·ªùi th√¢n thi·ªán                            ‚îÇ
‚îÇ  - Stream response t·ª´ng token                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              L∆ØU TR·ªÆ & G·ª¨I L·∫†I                              ‚îÇ
‚îÇ  - L∆∞u v√†o database (chat history)                          ‚îÇ
‚îÇ  - Cache response ph·ªï bi·∫øn (1 gi·ªù TTL)                      ‚îÇ
‚îÇ  - Stream v·ªÅ client qua WebSocket                           ‚îÇ
‚îÇ  - Ghi log cho ph√¢n t√≠ch                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Th√†nh ph·∫ßn h·ªá th·ªëng

```
FRONTEND (React)
‚îú‚îÄ‚îÄ Chat UI Component
‚îú‚îÄ‚îÄ Message Display
‚îú‚îÄ‚îÄ Input Handler
‚îî‚îÄ‚îÄ Real-time Updates (WebSocket)
    ‚îÇ
    ‚ñº
BACKEND (Node.js/Express)
‚îú‚îÄ‚îÄ WebSocket Server (Socket.IO)
‚îú‚îÄ‚îÄ Message Handler
‚îú‚îÄ‚îÄ Context Manager
‚îú‚îÄ‚îÄ Conversation Storage
‚îî‚îÄ‚îÄ AI Orchestrator
    ‚îÇ
    ‚ñº
AI PROVIDERS (Tier 1 + Tier 2)
‚îú‚îÄ‚îÄ Groq Llama 3 (Th∆∞·ªùng)
‚îú‚îÄ‚îÄ Google Gemini Flash (D·ª± ph√≤ng)
‚îî‚îÄ‚îÄ Qwen Coder (Code questions)
```

---

## üíª TRI·ªÇN KHAI BACKEND

### API WebSocket

**File:** `backend/src/modules/ai/ai.gateway.ts`

```typescript
import {
  WebSocketGateway,
  SubscribeMessage,
  OnGatewayConnection,
  OnGatewayDisconnect,
  MessageBody,
  ConnectedSocket,
  WsException
} from '@nestjs/websockets';
import { Socket } from 'socket.io';
import { AITutorService } from './services/ai-tutor.service';
import { AuthService } from '@/modules/auth/auth.service';

interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
}

interface UserContext {
  userId: string;
  courseId: string;
  conversationHistory: ChatMessage[];
}

@WebSocketGateway({
  namespace: '/ai/chat',
  cors: { origin: '*' },
  transports: ['websocket', 'polling']
})
export class AIChatGateway implements OnGatewayConnection, OnGatewayDisconnect {
  private userSessions: Map<string, UserContext> = new Map();
  private activeConnections: Map<string, Socket> = new Map();

  constructor(
    private aiTutorService: AITutorService,
    private authService: AuthService
  ) {}

  /**
   * X·ª≠ l√Ω khi client k·∫øt n·ªëi
   */
  async handleConnection(client: Socket) {
    try {
      // X√°c th·ª±c ng∆∞·ªùi d√πng
      const token = client.handshake.auth.token;
      const user = await this.authService.verifyToken(token);

      if (!user) {
        client.disconnect();
        return;
      }

      // L∆∞u k·∫øt n·ªëi
      this.activeConnections.set(user.id, client);
      
      // T·∫£i l·ªãch s·ª≠ h·ªôi tho·∫°i
      const courseId = client.handshake.query.courseId as string;
      const conversationHistory = 
        await this.aiTutorService.loadConversationHistory(user.id, courseId);

      this.userSessions.set(user.id, {
        userId: user.id,
        courseId,
        conversationHistory: conversationHistory || []
      });

      console.log(`[AI Chat] User ${user.id} connected`);
      client.emit('connected', { message: 'K·∫øt n·ªëi th√†nh c√¥ng' });

    } catch (error) {
      console.error('[AI Chat] Connection error:', error);
      client.disconnect();
    }
  }

  /**
   * X·ª≠ l√Ω khi client ng·∫Øt k·∫øt n·ªëi
   */
  handleDisconnect(client: Socket) {
    const userId = Array.from(this.activeConnections.entries())
      .find(([_, socket]) => socket === client)?.[0];

    if (userId) {
      this.activeConnections.delete(userId);
      this.userSessions.delete(userId);
      console.log(`[AI Chat] User ${userId} disconnected`);
    }
  }

  /**
   * X·ª≠ l√Ω tin nh·∫Øn t·ª´ client
   * Event: 'message'
   */
  @SubscribeMessage('message')
  async handleMessage(
    @ConnectedSocket() client: Socket,
    @MessageBody() payload: { text: string; courseId?: string }
  ) {
    try {
      const userId = Array.from(this.activeConnections.entries())
        .find(([_, socket]) => socket === client)?.[0];

      if (!userId) {
        throw new WsException('Ng∆∞·ªùi d√πng kh√¥ng ƒë∆∞·ª£c x√°c th·ª±c');
      }

      const userContext = this.userSessions.get(userId);
      if (!userContext) {
        throw new WsException('Phi√™n kh√¥ng t·ªìn t·∫°i');
      }

      // C·∫≠p nh·∫≠t courseId n·∫øu c√≥
      if (payload.courseId) {
        userContext.courseId = payload.courseId;
      }

      // G·ª≠i tr·∫°ng th√°i ƒëang x·ª≠ l√Ω
      client.emit('status', { state: 'typing' });

      // G·ªçi AI service ƒë·ªÉ t·∫°o ph·∫£n h·ªìi
      const response = await this.aiTutorService.chat(
        {
          message: payload.text,
          userId,
          courseId: userContext.courseId,
          conversationHistory: userContext.conversationHistory
        },
        (chunk) => {
          // Stream t·ª´ng ph·∫ßn c·ªßa response
          client.emit('response_chunk', { chunk });
        }
      );

      // C·∫≠p nh·∫≠t l·ªãch s·ª≠ h·ªôi tho·∫°i
      userContext.conversationHistory.push({
        role: 'user',
        content: payload.text,
        timestamp: new Date()
      });

      userContext.conversationHistory.push({
        role: 'assistant',
        content: response.text,
        timestamp: new Date()
      });

      // G·ª≠i ph·∫£n h·ªìi cu·ªëi c√πng
      client.emit('message_response', {
        text: response.text,
        metadata: {
          model: response.model,
          latency: response.latency,
          processedAt: new Date()
        }
      });

      // L∆∞u v√†o database
      await this.aiTutorService.saveChatMessage(
        userId,
        userContext.courseId,
        payload.text,
        response.text,
        response.model
      );

      client.emit('status', { state: 'idle' });

    } catch (error) {
      console.error('[AI Chat] Message error:', error);
      client.emit('error', {
        message: 'L·ªói x·ª≠ l√Ω c√¢u h·ªèi. Vui l√≤ng th·ª≠ l·∫°i.'
      });
    }
  }

  /**
   * L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i
   * Event: 'get_history'
   */
  @SubscribeMessage('get_history')
  async handleGetHistory(
    @ConnectedSocket() client: Socket,
    @MessageBody() payload: { limit?: number }
  ) {
    try {
      const userId = Array.from(this.activeConnections.entries())
        .find(([_, socket]) => socket === client)?.[0];

      if (!userId) {
        throw new WsException('Ng∆∞·ªùi d√πng kh√¥ng ƒë∆∞·ª£c x√°c th·ª±c');
      }

      const userContext = this.userSessions.get(userId);
      const history = await this.aiTutorService.getConversationHistory(
        userId,
        userContext?.courseId,
        payload.limit || 20
      );

      client.emit('history', { messages: history });

    } catch (error) {
      client.emit('error', { message: 'L·ªói l·∫•y l·ªãch s·ª≠' });
    }
  }

  /**
   * X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i
   * Event: 'clear_history'
   */
  @SubscribeMessage('clear_history')
  async handleClearHistory(@ConnectedSocket() client: Socket) {
    try {
      const userId = Array.from(this.activeConnections.entries())
        .find(([_, socket]) => socket === client)?.[0];

      if (!userId) {
        throw new WsException('Ng∆∞·ªùi d√πng kh√¥ng ƒë∆∞·ª£c x√°c th·ª±c');
      }

      const userContext = this.userSessions.get(userId);
      await this.aiTutorService.clearConversationHistory(
        userId,
        userContext?.courseId
      );

      userContext!.conversationHistory = [];
      client.emit('history_cleared', { message: 'L·ªãch s·ª≠ ƒë√£ x√≥a' });

    } catch (error) {
      client.emit('error', { message: 'L·ªói x√≥a l·ªãch s·ª≠' });
    }
  }
}
```

### AI Tutor Service

**File:** `backend/src/modules/ai/services/ai-tutor.service.ts`

```typescript
import { Injectable } from '@nestjs/common';
import { AIOrchestrator } from './ai-orchestrator';
import { GroqService } from './providers/groq.service';
import { GoogleAIService } from './providers/google-ai.service';
import { ProxyPalService } from './providers/proxypal.service';
import { ChatHistory } from '@/database/models/ChatHistory';
import Redis from 'ioredis';

interface ChatRequest {
  message: string;
  userId: string;
  courseId: string;
  conversationHistory: Array<{ role: string; content: string }>;
}

interface ChatResponse {
  text: string;
  model: string;
  latency: number;
}

@Injectable()
export class AITutorService {
  private orchestrator: AIOrchestrator;
  private groq: GroqService;
  private google: GoogleAIService;
  private proxypal: ProxyPalService;
  private redis: Redis;

  constructor() {
    this.orchestrator = new AIOrchestrator();
    this.groq = new GroqService();
    this.google = new GoogleAIService();
    this.proxypal = new ProxyPalService();
    this.redis = new Redis({
      host: process.env.REDIS_HOST,
      port: Number(process.env.REDIS_PORT),
      db: 2
    });
  }

  /**
   * G·ª≠i tin nh·∫Øn v√† nh·∫≠n ph·∫£n h·ªìi t·ª´ AI
   */
  async chat(
    request: ChatRequest,
    onChunk?: (chunk: string) => void
  ): Promise<ChatResponse> {
    const startTime = Date.now();

    // Step 1: Ph√¢n lo·∫°i c√¢u h·ªèi
    const classification = this.classifyQuestion(request.message);
    console.log(`[AI Tutor] Question type: ${classification.type}`);

    // Step 2: Ch·ªçn m√¥ h√¨nh ph√π h·ª£p
    const modelSelection = this.selectModel(classification);
    console.log(`[AI Tutor] Selected model: ${modelSelection.provider}`);

    // Step 3: X√¢y d·ª±ng prompt v·ªõi ng·ªØ c·∫£nh
    const prompt = this.buildPrompt(request, classification);

    // Step 4: G·ªçi AI service
    let response: string;
    if (modelSelection.provider === 'groq') {
      response = await this.groq.generateContent({
        prompt,
        stream: true,
        onChunk
      });
    } else if (modelSelection.provider === 'google') {
      response = await this.google.generateContent({
        prompt,
        stream: true,
        onChunk
      });
    } else if (modelSelection.provider === 'proxypal') {
      response = await this.proxypal.generateContent({
        model: modelSelection.model,
        prompt,
        stream: true,
        onChunk
      });
    }

    const latency = Date.now() - startTime;

    return {
      text: response,
      model: modelSelection.model,
      latency
    };
  }

  /**
   * Ph√¢n lo·∫°i lo·∫°i c√¢u h·ªèi
   */
  private classifyQuestion(message: string): Classification {
    const lowerMessage = message.toLowerCase();

    // C√¢u h·ªèi v·ªÅ code
    if (this.containsCodeKeywords(lowerMessage)) {
      return {
        type: 'code',
        complexity: 'high',
        requiresCode: true
      };
    }

    // C√¢u h·ªèi c√≥ math/to√°n
    if (this.containsMathKeywords(lowerMessage)) {
      return {
        type: 'math',
        complexity: 'medium',
        requiresExplanation: true
      };
    }

    // C√¢u h·ªèi kh√≥ ho·∫∑c d√†i
    if (message.length > 200 || this.hasComplexStructure(message)) {
      return {
        type: 'complex',
        complexity: 'high',
        requiresDeepThinking: true
      };
    }

    // C√¢u h·ªèi ƒë∆°n gi·∫£n
    return {
      type: 'simple',
      complexity: 'low',
      requiresSpeed: true
    };
  }

  /**
   * Ch·ªçn m√¥ h√¨nh ph√π h·ª£p
   */
  private selectModel(classification: Classification): ModelSelection {
    // C√¢u h·ªèi code: D√πng Qwen Coder t·ª´ ProxyPal
    if (classification.type === 'code') {
      return {
        provider: 'proxypal',
        model: 'qwen3-coder-plus',
        rationale: 'Chuy√™n gia v·ªÅ code'
      };
    }

    // C√¢u h·ªèi ph·ª©c t·∫°p: D√πng Google Flash (context l·ªõn)
    if (classification.complexity === 'high' && classification.type !== 'code') {
      return {
        provider: 'google',
        model: 'gemini-1.5-flash',
        rationale: 'X·ª≠ l√Ω c√¢u h·ªèi ph·ª©c t·∫°p'
      };
    }

    // C√¢u h·ªèi ƒë∆°n gi·∫£n: D√πng Groq (c·ª±c nhanh)
    return {
      provider: 'groq',
      model: 'llama-3-70b-8192',
      rationale: 'C·∫ßn t·ªëc ƒë·ªô cao'
    };
  }

  /**
   * X√¢y d·ª±ng prompt v·ªõi ng·ªØ c·∫£nh
   */
  private buildPrompt(
    request: ChatRequest,
    classification: Classification
  ): string {
    const recentHistory = request.conversationHistory.slice(-5); // 5 tin nh·∫Øn g·∫ßn nh·∫•t

    const systemPrompt = `B·∫°n l√† m·ªôt tr·ª£ gi·∫£ng th√¥ng minh, th√¢n thi·ªán v√† h·ªØu √≠ch cho sinh vi√™n.
    
H∆∞·ªõng d·∫´n:
- Tr·∫£ l·ªùi r√µ r√†ng v√† d·ªÖ hi·ªÉu
- Cung c·∫•p v√≠ d·ª• khi c·∫ßn thi·∫øt
- Khuy·∫øn kh√≠ch sinh vi√™n t∆∞ duy ƒë·ªôc l·∫≠p
- N·∫øu c√¢u h·ªèi kh√≥, h√£y chia th√†nh b∆∞·ªõc nh·ªè
- Lu√¥n th√¢n thi·ªán v√† t√≠ch c·ª±c
${classification.type === 'code' ? '- Cung c·∫•p code examples v·ªõi gi·∫£i th√≠ch' : ''}
${classification.type === 'math' ? '- Hi·ªÉn th·ªã c√°c b∆∞·ªõc gi·∫£i chi ti·∫øt' : ''}
`;

    const conversationContext = recentHistory
      .map(msg => `${msg.role === 'user' ? 'Sinh vi√™n' : 'Tr·ª£ gi·∫£ng'}: ${msg.content}`)
      .join('\n');

    return `${systemPrompt}

L·ªãch s·ª≠ h·ªôi tho·∫°i:
${conversationContext}

Sinh vi√™n: ${request.message}

Tr·ª£ gi·∫£ng:`;
  }

  /**
   * L∆∞u tin nh·∫Øn chat v√†o database
   */
  async saveChatMessage(
    userId: string,
    courseId: string,
    userMessage: string,
    aiResponse: string,
    model: string
  ): Promise<void> {
    try {
      await ChatHistory.create({
        userId,
        courseId,
        userMessage,
        aiResponse,
        model,
        createdAt: new Date()
      });
    } catch (error) {
      console.error('[AI Tutor] Error saving chat:', error);
    }
  }

  /**
   * T·∫£i l·ªãch s·ª≠ h·ªôi tho·∫°i
   */
  async loadConversationHistory(
    userId: string,
    courseId: string,
    limit: number = 20
  ): Promise<ChatMessage[]> {
    // Ki·ªÉm tra cache tr∆∞·ªõc
    const cacheKey = `chat:history:${userId}:${courseId}`;
    const cached = await this.redis.get(cacheKey);
    if (cached) {
      return JSON.parse(cached);
    }

    // L·∫•y t·ª´ database
    const messages = await ChatHistory.findAll({
      where: { userId, courseId },
      order: [['createdAt', 'ASC']],
      limit,
      raw: true
    });

    const history = messages.flatMap(msg => [
      { role: 'user', content: msg.userMessage },
      { role: 'assistant', content: msg.aiResponse }
    ]);

    // L∆∞u cache 1 gi·ªù
    await this.redis.setex(cacheKey, 3600, JSON.stringify(history));

    return history;
  }

  /**
   * L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i
   */
  async getConversationHistory(
    userId: string,
    courseId: string,
    limit: number = 20
  ) {
    return await this.loadConversationHistory(userId, courseId, limit);
  }

  /**
   * X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i
   */
  async clearConversationHistory(userId: string, courseId: string): Promise<void> {
    await ChatHistory.destroy({
      where: { userId, courseId }
    });

    // X√≥a cache
    const cacheKey = `chat:history:${userId}:${courseId}`;
    await this.redis.del(cacheKey);
  }

  private containsCodeKeywords(text: string): boolean {
    const keywords = ['code', 'function', 'class', 'variable', 'loop', 'array', 'object', 'api'];
    return keywords.some(kw => text.includes(kw));
  }

  private containsMathKeywords(text: string): boolean {
    const keywords = ['t√≠nh', 'c√¥ng th·ª©c', 'ph∆∞∆°ng tr√¨nh', 's·ªë', 'to√°n', 'gi·∫£i'];
    return keywords.some(kw => text.includes(kw));
  }

  private hasComplexStructure(text: string): boolean {
    return text.split(' ').length > 50 || text.split('\n').length > 3;
  }
}
```

---

## üé® TRI·ªÇN KHAI FRONTEND

### Chat Component

**File:** `frontend/src/features/student/components/AIChatPanel.tsx`

```typescript
import React, { useState, useEffect, useRef } from 'react';
import { useSocket } from '@/hooks/useSocket';
import { Message, ChatBubble } from '@/components/chat';
import { Spinner } from '@/components/ui';

interface ChatMessage {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  model?: string;
}

interface AIChatPanelProps {
  courseId: string;
  visible: boolean;
}

export const AIChatPanel: React.FC<AIChatPanelProps> = ({
  courseId,
  visible
}) => {
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);
  const [isStreaming, setIsStreaming] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  
  const socket = useSocket('ai/chat', {
    query: { courseId }
  });

  useEffect(() => {
    if (!socket) return;

    // Nh·∫≠n l·ªãch s·ª≠ h·ªôi tho·∫°i
    socket.on('history', (data: { messages: ChatMessage[] }) => {
      setMessages(data.messages);
    });

    // Nh·∫≠n t·ª´ng ph·∫ßn c·ªßa response
    socket.on('response_chunk', (data: { chunk: string }) => {
      setIsStreaming(true);
      setMessages(prev => {
        const updated = [...prev];
        const lastMsg = updated[updated.length - 1];
        if (lastMsg && lastMsg.role === 'assistant') {
          lastMsg.content += data.chunk;
        }
        return updated;
      });
    });

    // Nh·∫≠n ph·∫£n h·ªìi cu·ªëi c√πng
    socket.on('message_response', (data: any) => {
      setIsStreaming(false);
      setLoading(false);
      setInput('');
    });

    // L·∫•y l·ªãch s·ª≠ khi k·∫øt n·ªëi
    socket.emit('get_history', { limit: 20 });

    return () => {
      socket.off('history');
      socket.off('response_chunk');
      socket.off('message_response');
    };
  }, [socket]);

  useEffect(() => {
    // Auto scroll xu·ªëng cu·ªëi
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  const handleSendMessage = () => {
    if (!input.trim() || loading) return;

    const userMessage: ChatMessage = {
      id: `msg-${Date.now()}`,
      role: 'user',
      content: input,
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setLoading(true);

    const assistantMessage: ChatMessage = {
      id: `msg-${Date.now()}-ai`,
      role: 'assistant',
      content: '',
      timestamp: new Date()
    };
    setMessages(prev => [...prev, assistantMessage]);

    socket?.emit('message', {
      text: input,
      courseId
    });
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  if (!visible) return null;

  return (
    <div className="ai-chat-panel bg-white rounded-lg shadow-lg">
      <div className="chat-header bg-blue-600 text-white p-4">
        <h3 className="font-bold">ü§ñ Tr·ª£ Gi·∫£ng AI</h3>
        <p className="text-sm opacity-90">H·ªèi b·∫•t k·ª≥ c√¢u h·ªèi n√†o v·ªÅ kh√≥a h·ªçc</p>
      </div>

      <div className="chat-messages flex-1 overflow-y-auto p-4 h-96">
        {messages.length === 0 ? (
          <div className="text-center text-gray-400 py-8">
            <p>B·∫Øt ƒë·∫ßu cu·ªôc h·ªôi tho·∫°i b·∫±ng c√°ch ƒë·∫∑t c√¢u h·ªèi</p>
          </div>
        ) : (
          messages.map((msg, idx) => (
            <ChatBubble
              key={msg.id}
              message={msg.content}
              isUser={msg.role === 'user'}
              timestamp={msg.timestamp}
              model={msg.model}
            />
          ))
        )}

        {loading && isStreaming && (
          <div className="flex items-center gap-2 text-gray-500">
            <Spinner size="sm" />
            <span>Tr·ª£ gi·∫£ng ƒëang suy nghƒ©...</span>
          </div>
        )}

        <div ref={messagesEndRef} />
      </div>

      <div className="chat-input border-t p-4 flex gap-2">
        <textarea
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyPress={handleKeyPress}
          placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n..."
          rows={3}
          className="flex-1 p-2 border rounded focus:outline-none focus:ring-2 focus:ring-blue-500"
          disabled={loading}
        />
        <button
          onClick={handleSendMessage}
          disabled={loading || !input.trim()}
          className="btn btn-primary px-6 h-full"
        >
          {loading ? <Spinner size="sm" /> : 'G·ª≠i'}
        </button>
      </div>
    </div>
  );
};
```

---

## ‚öôÔ∏è C·∫§U H√åNH

**File:** `backend/.env`

```bash
# AI Tutor Configuration
AI_TUTOR_DEFAULT_MODEL=llama-3-70b-8192
AI_TUTOR_ENABLE_STREAMING=true
AI_TUTOR_RESPONSE_TIMEOUT=30000
AI_TUTOR_CACHE_TTL=3600

# Chat History
CHAT_HISTORY_RETENTION_DAYS=90
CHAT_HISTORY_MAX_MESSAGES=1000

# WebSocket
WEBSOCKET_PING_INTERVAL=30000
WEBSOCKET_PING_TIMEOUT=5000
```

---

## üß™ KI·ªÇM TH·ª¨

```typescript
describe('AI Tutor Service', () => {
  it('should respond to simple question using Groq', async () => {
    const response = await aiTutorService.chat({
      message: 'React l√† g√¨?',
      userId: 'test-user',
      courseId: 'test-course',
      conversationHistory: []
    });

    expect(response.model).toBe('llama-3-70b-8192');
    expect(response.latency).toBeLessThan(2000);
    expect(response.text.length).toBeGreaterThan(0);
  });

  it('should respond to code question using Qwen', async () => {
    const response = await aiTutorService.chat({
      message: 'Vi·∫øt function ƒë·ªÉ t√≠nh t·ªïng array?',
      userId: 'test-user',
      courseId: 'test-course',
      conversationHistory: []
    });

    expect(response.model).toContain('qwen');
    expect(response.text).toContain('function');
  });
});
```

---

## üìö LI√äN QUAN

- **Tr∆∞·ªõc:** [04_QUIZ_GENERATOR.md](04_QUIZ_GENERATOR.md)
- **Ti·∫øp:** [06_AI_GRADER.md](06_AI_GRADER.md)
- **Ki·∫øn tr√∫c:** [01_OVERVIEW.md](01_OVERVIEW.md)

---

**Phi√™n b·∫£n:** 2.0  
**C·∫≠p nh·∫≠t l·∫ßn cu·ªëi:** 17 th√°ng 12, 2025
