# ğŸ¬ Video Understanding V2 (STT + Vision) â€” Thay tháº¿ Ä‘á»c video trá»±c tiáº¿p

**TÃ i liá»‡u (Document):** 14 - Video Understanding V2  
**PhiÃªn báº£n (Version):** 1.0  
**Cáº­p nháº­t gáº§n nháº¥t (Last Updated):** December 27, 2025  
**Má»¥c tiÃªu:** KhÃ´i phá»¥c vÃ  nÃ¢ng cáº¥p kháº£ nÄƒng â€œphÃ¢n tÃ­ch video bÃ i giáº£ngâ€ khi ProxyPal khÃ´ng cÃ²n há»— trá»£ `gemini-3-pro-preview`.

---

## 1) Bá»‘i cáº£nh hiá»‡n táº¡i trong codebase

- Backend cÃ³ `LessonAnalysisService.analyzeVideoContent()` Ä‘ang gá»i `GeminiVideoService` (direct Gemini API) vá»›i biáº¿n `GEMINI_VIDEO_MODEL` (default: `gemini-3-pro-preview`).
- TÃ i liá»‡u cÅ© tá»«ng Æ°u tiÃªn ProxyPal Gemini cho video understanding, nhÆ°ng hiá»‡n ProxyPal khÃ´ng cÃ²n support model Ä‘Ã³.
- Trong `env.ai.groq.models` Ä‘Ã£ cÃ³:
  - `speech`: `whisper-large-v3`
  - `vision`: `llama-4-scout`
  nhÆ°ng chÆ°a cÃ³ code pipeline video.

---

## 2) Káº¿t luáº­n kháº£ thi (Verify)

**CÃ³ thá»ƒ â€œphÃ¢n tÃ­ch videoâ€ mÃ  khÃ´ng cáº§n model Ä‘á»c video trá»±c tiáº¿p** báº±ng cÃ¡ch:
- **Speech-to-Text** Ä‘á»ƒ láº¥y ná»™i dung lá»i nÃ³i (transcript)
- **Vision** Ä‘á»ƒ láº¥y ná»™i dung hÃ¬nh áº£nh quan trá»ng (slide/diagram/whiteboard)
- **Reasoning** Ä‘á»ƒ há»£p nháº¥t (fusion) vÃ  táº¡o output chuáº©n (summary/key points/rubric/quiz).

ÄÃ¢y lÃ  hÆ°á»›ng phá»• biáº¿n khi khÃ´ng cÃ³ video-native model.

---

## 3) Kiáº¿n trÃºc pipeline Ä‘á» xuáº¥t

### 3.1 Input
- `videoUrl` (YouTube / public MP4 / R2 object public/signed URL)
- hoáº·c upload video lÃªn backend (multipart) Ä‘á»ƒ xá»­ lÃ½ server-side

### 3.2 Processing steps (deterministic)

**Step A â€” Fetch & Cache**
- Download video vá» temp storage (giá»›i háº¡n size).
- Cache theo hash(URL + etag) Ä‘á»ƒ trÃ¡nh xá»­ lÃ½ láº¡i.

**Step B â€” Audio extraction**
- DÃ¹ng `ffmpeg` Ä‘á»ƒ trÃ­ch audio track â†’ `audio.wav` hoáº·c `audio.mp3`.
- Option: chunk audio theo má»—i 5â€“10 phÃºt náº¿u video dÃ i.

**Step C â€” Speech to Text (Groq Whisper)**
- Gá»i endpoint STT Ä‘á»ƒ táº¡o transcript.
- NÃªn láº¥y thÃªm timestamps (náº¿u API há»— trá»£) hoáº·c tá»± chunk Ä‘á»ƒ suy timestamps.

**Step D â€” Frame sampling (Keyframes)**
- Sample frame theo interval (vÃ­ dá»¥ 1 frame/10â€“20s), hoáº·c detect scene changes.
- LÆ°u frame (JPEG/PNG) vÃ  limit sá»‘ frame (vÃ­ dá»¥ tá»‘i Ä‘a 60â€“120 áº£nh).

**Step E â€” Vision caption / OCR**
- Vá»›i má»—i frame:
  - caption: â€œwhat is shownâ€
  - OCR: text trÃªn slide/whiteboard
  - detect diagrams/code snippets (náº¿u cáº§n)

**Step F â€” Fusion (Reasoning model)**
- Input: transcript + list frame findings (caption/OCR + timestamps)
- Output: JSON chuáº©n hoÃ¡ cho LMS:
  - `transcript` (raw hoáº·c cleaned)
  - `keyPoints` (5â€“10)
  - `summary` (3â€“7 cÃ¢u)
  - `slideOutline` (dÃ n Ã½ theo slide)
  - `glossary` (term â†’ definition)
  - `quizBlueprint` (optional)

---

## 4) Output schema Ä‘á» xuáº¥t (Ä‘á»ƒ thay tháº¿ `VideoAnalysisResult`)

```json
{
  "transcript": "...",
  "language": "vi|en|mixed",
  "keyPoints": ["..."],
  "summary": "...",
  "duration": 0,
  "timeline": [
    {
      "t": 120,
      "type": "speech|slide|diagram",
      "text": "...",
      "source": "stt|vision"
    }
  ],
  "slideOutline": [
    {
      "tStart": 300,
      "tEnd": 420,
      "title": "...",
      "bullets": ["..."],
      "ocr": "..."
    }
  ],
  "metadata": {
    "providers": {
      "stt": {"provider": "groq", "model": "whisper-large-v3"},
      "vision": {"provider": "groq", "model": "llama-4-scout"},
      "fusion": {"provider": "groq", "model": "<reasoning-model>"}
    }
  }
}
```

---

## 5) Cáº¥u hÃ¬nh (giá»¯ cÅ© + thÃªm má»›i)

### 5.1 Giá»¯ cáº¥u hÃ¬nh cÅ© (legacy)
- `GEMINI_API_KEY`
- `GEMINI_VIDEO_MODEL` (Ä‘á»ƒ náº¿u sau nÃ y Gemini/ProxyPal quay láº¡i há»— trá»£ thÃ¬ báº­t láº¡i nhanh)

### 5.2 Cáº¥u hÃ¬nh má»›i (Video V2)
Äá» xuáº¥t thÃªm env vars (khÃ´ng phÃ¡ tÆ°Æ¡ng thÃ­ch):

```env
# Toggle
AI_VIDEO_PIPELINE=v2   # legacy|v2

# Limits
AI_VIDEO_MAX_DOWNLOAD_MB=100
AI_VIDEO_MAX_FRAMES=90
AI_VIDEO_FRAME_INTERVAL_SEC=15
AI_VIDEO_AUDIO_CHUNK_MIN=10

# Tooling
FFMPEG_PATH=ffmpeg

# Groq models
GROQ_MODEL_SPEECH=whisper-large-v3
GROQ_MODEL_VISION=llama-4-scout
GROQ_MODEL_REASONING=<set-to-reasoning-model>
```

---

## 6) Rá»§i ro & cÃ¡ch giáº£m

- **Video dÃ i** â†’ chunk audio + háº¡n cháº¿ frames.
- **Video cháº¥t lÆ°á»£ng Ã¢m thanh kÃ©m** â†’ STT sai â†’ cáº§n post-processing: punctuation, cleaning.
- **Slide nhá»/blur** â†’ OCR fail â†’ tÄƒng quality frame, sample Ã­t nhÆ°ng â€œÄ‘Ãºng lÃºcâ€ (scene-change).
- **YouTube/DRM/private R2** â†’ khÃ´ng download Ä‘Æ°á»£c â†’ yÃªu cáº§u signed URL hoáº·c upload trá»±c tiáº¿p.

---

## 7) TÃ­ch há»£p vÃ o LMS (Ä‘iá»ƒm gáº¯n)

- `LessonAnalysisService.analyzeVideoContent()`:
  - giá»¯ nhÃ¡nh legacy (GeminiVideoService)
  - thÃªm nhÃ¡nh v2: gá»i `VideoUnderstandingV2Service` (STT+Vision)
- `AIGraderService`:
  - thÃªm path xá»­ lÃ½ bÃ i ná»™p áº£nh (vision â†’ text â†’ grade)
- `QuizGeneratorService`:
  - náº¿u lesson lÃ  video: dÃ¹ng transcript + slideOutline Ä‘á»ƒ generate quiz cháº¥t lÆ°á»£ng hÆ¡n

Roadmap code-level náº±m á»Ÿ: **15_BACKEND_CHANGES_ROADMAP_GROQ_MULTIMODAL.md**.
